{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Lab2_DL_part1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Voveka98/ml-mipt/blob/master/Lab2_DL_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp-icTwuuhkB",
        "colab_type": "text"
      },
      "source": [
        "## Lab 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaKffLt9uhkD",
        "colab_type": "text"
      },
      "source": [
        "### Part 1. Overfit it (1.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NahvH6zcuhkG",
        "colab_type": "text"
      },
      "source": [
        "Будем работать с датасетом [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) (*hint: он доступен в torchvision*).\n",
        "\n",
        "Ваша задача состоит в следующем:\n",
        "1. Обучить сеть, которая покажет >= 0.92 test accuracy.\n",
        "2. Пронаблюдать и продемонстрировать процесс переобучения сети с увеличением числа параметров (==нейронов) и/или числа слоев и продемонстрировать это наглядно (например, на графиках).\n",
        "3. Попробовать частично справиться с переобучением с помощью подходящих приемов (Dropout/batchnorm/augmentation etc.)\n",
        "\n",
        "*Примечание*: Пункты 2 и 3 взаимосвязаны, в п.3 Вам прелагается сделать полученную в п.2 сеть менее склонной к переобучению. Пункт 1 является независимым от пунктов 2 и 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQne1XHBuhkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your great code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSn0Vq9ouhkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from collections import OrderedDict\n",
        "from torch import nn, optim\n",
        "import seaborn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVUhJ5OTuhkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) \n",
        "# Download and load the training data \n",
        "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform) \n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True) \n",
        "\n",
        "# Download and load the test data \n",
        "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform) \n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u5HzOU6uhkS",
        "colab_type": "code",
        "outputId": "d88ba882-a20b-4a28-e5f1-2f1289c710c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "trainset.train_labels"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 0, 0,  ..., 3, 0, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYFTh3v12lLG",
        "colab_type": "code",
        "outputId": "8c62c684-bb15-4ddc-a901-55ead2422fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(trainset.data[1].reshape((28, 28)), cmap=\"gray\")\n",
        "print('lol',trainset.data[0].shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lol torch.Size([28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFT5jMPCuy3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neuro_net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Neuro_net,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=15, kernel_size=5,padding=2)\n",
        "    #x.shape = 8*28*28\n",
        "    #после макспула 8*14*14\n",
        "    # self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3,padding=1)\n",
        "    #x.shape = 16*14*14\n",
        "    #после макспула 16*7*7\n",
        "    # self.conv3 = nn.Conv2d(in_channels=16, out_channels=36,kernel_size=3, padding=1)\n",
        "    #x.shape = 36*7*7\n",
        "    #после макспула 36*3*3\n",
        "    self.lin1 = nn.Linear(15*14*14,1328)\n",
        "    self.lin = nn.Linear(1328,768)\n",
        "    self.lin2 = nn.Linear(768, 384)\n",
        "    self.lin3 = nn.Linear(384, 128)\n",
        "    self.lin4 = nn.Linear(128, 80)\n",
        "    # self.lin5 = nn.Linear(100, 50)\n",
        "    self.lin6 = nn.Linear(80,10)\n",
        "    self.act = torch.nn.Tanh()\n",
        "    self.drop = nn.Dropout(p=0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
        "    # x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
        "    # x = F.max_pool2d(F.relu(self.conv3(x)),2)\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    \n",
        "    x = self.drop(F.relu(self.lin1(x)))\n",
        "    x = F.relu(self.lin(x))\n",
        "    x = F.relu(self.lin2(x))\n",
        "    x = F.relu(self.lin3(x))\n",
        "    x = F.relu(self.lin4(x))\n",
        "    # x = self.act(self.lin5(x))\n",
        "    x = self.lin6(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaU_iM_bw3pT",
        "colab_type": "code",
        "outputId": "53f4cae7-3a81-46c2-b240-348a0a8d7e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = Neuro_net().to(device)\n",
        "\n",
        "#loss\n",
        "criterion = torch.nn.modules.CrossEntropyLoss()\n",
        "\n",
        "#функция оптимизации\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  run_loss = 0\n",
        "  \n",
        "  for images,labels in trainloader:\n",
        "    '''обнуляем градиент, иначе, так как у нас chain rule в вычислении градиента,\n",
        "    то через пару итераций мы просто забьём всю RAM ненужными цифрами'''\n",
        "    optimizer.zero_grad()              \n",
        "    '''подаём изображение на вход сети (forward pass по сути дела)'''\n",
        "    log_ps = model(images)                     \n",
        "    '''вычисляем loss'''\n",
        "    loss = criterion(log_ps, labels)       \n",
        "    '''backward pass'''\n",
        "    loss.backward()                            \n",
        "    optimizer.step()                           \n",
        "    run_loss += loss.item()                \n",
        "     \n",
        "    \n",
        "  test_loss = 0\n",
        "  accuracy = 0\n",
        "    \n",
        "  # Turn off the gradients\n",
        "  with torch.no_grad():\n",
        "    # цикл по валидационному датасету\n",
        "    for images, labels in testloader:\n",
        "      log_ps = model(images)                                 \n",
        "      # ps = torch.exp(log_ps)                                 \n",
        "      test_loss += criterion(log_ps, labels)             \n",
        "      top_p, top_class = log_ps.topk(1,dim=1)                    \n",
        "      equals = top_class == labels.view(*top_class.shape)   \n",
        "      accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "    \n",
        "  # записываем средние лоссы на трейне и тесте       \n",
        "  train_losses.append(run_loss/len(trainloader))\n",
        "  test_losses.append(test_loss/len(testloader)) \n",
        "\n",
        "  #выводим промежуточные результаты\n",
        "  print(\"Epoch: {}/{}.. \".format(i+1, num_epochs),\n",
        "              \"Training Loss: {:.3f} \".format(run_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f} \".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "  "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/50..  Training Loss: 0.783  Test Loss: 0.514  Test Accuracy: 0.810\n",
            "Epoch: 2/50..  Training Loss: 0.448  Test Loss: 0.424  Test Accuracy: 0.849\n",
            "Epoch: 3/50..  Training Loss: 0.378  Test Loss: 0.375  Test Accuracy: 0.865\n",
            "Epoch: 4/50..  Training Loss: 0.335  Test Loss: 0.359  Test Accuracy: 0.872\n",
            "Epoch: 5/50..  Training Loss: 0.305  Test Loss: 0.331  Test Accuracy: 0.886\n",
            "Epoch: 6/50..  Training Loss: 0.283  Test Loss: 0.311  Test Accuracy: 0.888\n",
            "Epoch: 7/50..  Training Loss: 0.264  Test Loss: 0.318  Test Accuracy: 0.885\n",
            "Epoch: 8/50..  Training Loss: 0.249  Test Loss: 0.309  Test Accuracy: 0.893\n",
            "Epoch: 9/50..  Training Loss: 0.233  Test Loss: 0.326  Test Accuracy: 0.883\n",
            "Epoch: 10/50..  Training Loss: 0.220  Test Loss: 0.285  Test Accuracy: 0.898\n",
            "Epoch: 11/50..  Training Loss: 0.206  Test Loss: 0.275  Test Accuracy: 0.902\n",
            "Epoch: 12/50..  Training Loss: 0.194  Test Loss: 0.276  Test Accuracy: 0.901\n",
            "Epoch: 13/50..  Training Loss: 0.182  Test Loss: 0.268  Test Accuracy: 0.906\n",
            "Epoch: 14/50..  Training Loss: 0.171  Test Loss: 0.280  Test Accuracy: 0.903\n",
            "Epoch: 15/50..  Training Loss: 0.160  Test Loss: 0.279  Test Accuracy: 0.906\n",
            "Epoch: 16/50..  Training Loss: 0.148  Test Loss: 0.272  Test Accuracy: 0.908\n",
            "Epoch: 17/50..  Training Loss: 0.136  Test Loss: 0.295  Test Accuracy: 0.906\n",
            "Epoch: 18/50..  Training Loss: 0.129  Test Loss: 0.280  Test Accuracy: 0.913\n",
            "Epoch: 19/50..  Training Loss: 0.119  Test Loss: 0.276  Test Accuracy: 0.913\n",
            "Epoch: 20/50..  Training Loss: 0.111  Test Loss: 0.292  Test Accuracy: 0.909\n",
            "Epoch: 21/50..  Training Loss: 0.101  Test Loss: 0.298  Test Accuracy: 0.912\n",
            "Epoch: 22/50..  Training Loss: 0.093  Test Loss: 0.317  Test Accuracy: 0.909\n",
            "Epoch: 23/50..  Training Loss: 0.086  Test Loss: 0.298  Test Accuracy: 0.915\n",
            "Epoch: 24/50..  Training Loss: 0.078  Test Loss: 0.343  Test Accuracy: 0.911\n",
            "Epoch: 25/50..  Training Loss: 0.073  Test Loss: 0.344  Test Accuracy: 0.915\n",
            "Epoch: 26/50..  Training Loss: 0.067  Test Loss: 0.360  Test Accuracy: 0.912\n",
            "Epoch: 27/50..  Training Loss: 0.063  Test Loss: 0.347  Test Accuracy: 0.914\n",
            "Epoch: 28/50..  Training Loss: 0.058  Test Loss: 0.363  Test Accuracy: 0.916\n",
            "Epoch: 29/50..  Training Loss: 0.056  Test Loss: 0.354  Test Accuracy: 0.914\n",
            "Epoch: 30/50..  Training Loss: 0.050  Test Loss: 0.397  Test Accuracy: 0.915\n",
            "Epoch: 31/50..  Training Loss: 0.047  Test Loss: 0.385  Test Accuracy: 0.912\n",
            "Epoch: 32/50..  Training Loss: 0.042  Test Loss: 0.403  Test Accuracy: 0.912\n",
            "Epoch: 33/50..  Training Loss: 0.038  Test Loss: 0.430  Test Accuracy: 0.913\n",
            "Epoch: 34/50..  Training Loss: 0.038  Test Loss: 0.445  Test Accuracy: 0.911\n",
            "Epoch: 35/50..  Training Loss: 0.036  Test Loss: 0.450  Test Accuracy: 0.911\n",
            "Epoch: 36/50..  Training Loss: 0.031  Test Loss: 0.435  Test Accuracy: 0.917\n",
            "Epoch: 37/50..  Training Loss: 0.035  Test Loss: 0.432  Test Accuracy: 0.914\n",
            "Epoch: 38/50..  Training Loss: 0.029  Test Loss: 0.436  Test Accuracy: 0.914\n",
            "Epoch: 39/50..  Training Loss: 0.029  Test Loss: 0.458  Test Accuracy: 0.913\n",
            "Epoch: 40/50..  Training Loss: 0.026  Test Loss: 0.485  Test Accuracy: 0.912\n",
            "Epoch: 41/50..  Training Loss: 0.027  Test Loss: 0.471  Test Accuracy: 0.914\n",
            "Epoch: 42/50..  Training Loss: 0.025  Test Loss: 0.515  Test Accuracy: 0.911\n",
            "Epoch: 43/50..  Training Loss: 0.024  Test Loss: 0.498  Test Accuracy: 0.913\n",
            "Epoch: 44/50..  Training Loss: 0.024  Test Loss: 0.490  Test Accuracy: 0.914\n",
            "Epoch: 45/50..  Training Loss: 0.021  Test Loss: 0.521  Test Accuracy: 0.912\n",
            "Epoch: 46/50..  Training Loss: 0.022  Test Loss: 0.478  Test Accuracy: 0.915\n",
            "Epoch: 47/50..  Training Loss: 0.020  Test Loss: 0.522  Test Accuracy: 0.912\n",
            "Epoch: 48/50..  Training Loss: 0.020  Test Loss: 0.510  Test Accuracy: 0.913\n",
            "Epoch: 49/50..  Training Loss: 0.020  Test Loss: 0.521  Test Accuracy: 0.912\n",
            "Epoch: 50/50..  Training Loss: 0.018  Test Loss: 0.512  Test Accuracy: 0.915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW67HT6Ew9qF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}